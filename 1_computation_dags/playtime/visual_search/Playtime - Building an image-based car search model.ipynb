{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, google_images_download, faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Download the datasets\n",
    "\n",
    "First we will get a table of year, brand and makes of cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -Rf dataset\n",
    "mkdir -pv dataset\n",
    "git clone git@github.com:arthurkao/vehicle-make-model-data.git dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "car_make_data = pd.read_csv('dataset/csv_data.csv')\n",
    "\n",
    "car_make_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we build the queries we will use to search google images\n",
    "def cols_to_query(row):\n",
    "    return ' '.join([str(row['year']), row['make'], row['model']]).lower()\n",
    "                     \n",
    "car_make_data['queries'] = car_make_data.apply(cols_to_query, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we retrieve images from google images using the \n",
    "# `google_images_download` python package\n",
    "from time import time\n",
    "from google_images_download import google_images_download  \n",
    "\n",
    "client = google_images_download.googleimagesdownload()\n",
    "\n",
    "n_samples = 10\n",
    "n_images_per_sample = 100\n",
    "\n",
    "sample_queries = car_make_data['queries'].sample(n_samples, random_state=42)\n",
    "\n",
    "for (i, (_, query)) in enumerate(sample_queries.iteritems()):\n",
    "    arguments = {\n",
    "        \"keywords\": query,\n",
    "        \"limit\": n_images_per_sample,\n",
    "        \"size\": \"medium\",\n",
    "        \"format\": \"png\",\n",
    "        \"output_directory\": 'dataset/'\n",
    "    }\n",
    "    start_time = time()\n",
    "    paths, n_downloaded = client.download(arguments)\n",
    "    \n",
    "    print('Downloaded {} images for `{}` ({}/{}) in {:.2f}s'.format(\n",
    "        n_downloaded, query, i, n_samples, time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "car_class_to_paths = {}\n",
    "for folder in os.listdir('dataset/'):\n",
    "    folder_path = os.path.join('dataset', folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(folder)\n",
    "        car_class_to_paths[folder] = []\n",
    "        for file in os.listdir(folder_path):\n",
    "            car_class_to_paths[folder].append(\n",
    "                os.path.join(folder_path, file))\n",
    "\n",
    "car_class_to_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Generate image representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = len([v for vs in car_class_to_paths.values() for v in vs])\n",
    "features = []\n",
    "labels = []\n",
    "paths = []\n",
    "i = 0\n",
    "max_samples = 500\n",
    "for (label, label_paths) in car_class_to_paths.items():\n",
    "    print(label)\n",
    "    for label_path in label_paths:\n",
    "        print(label_path)\n",
    "        try:\n",
    "            img = image.load_img(label_path, target_size=(224, 224))\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            features.append(model.predict(x))\n",
    "            labels.append(label)\n",
    "            paths.append(label_path)\n",
    "            i += 1\n",
    "            if i > max_samples:\n",
    "                break\n",
    "                break\n",
    "\n",
    "features_arr = np.concatenate(features, axis=0)\n",
    "print('Representations computed for {} images'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Index into an approx Nearest Neighbor structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss  \n",
    "import tempfile\n",
    "import urllib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def display_from_url(url, ax=plt.gca()):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        img = plt.imread(response, 0)\n",
    "        return ax.imshow(img)\n",
    "\n",
    "\n",
    "def display_from_path(path, ax=plt.gca()):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = plt.imread(f, 0)\n",
    "        return ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighborsIndex:\n",
    "    def __init__(self, representations, paths, model, model_input_size=(224, 224)):      \n",
    "        self.index = faiss.IndexFlatL2(representations.shape[1])\n",
    "        self.index.add(representations.astype(np.float32))\n",
    "        print(\"{}/{} documents indexed\".format(self.index.ntotal, \n",
    "                                               representations.shape[0]))\n",
    "        self.paths = paths\n",
    "        self.model = model\n",
    "        self.model_input_size = model_input_size\n",
    "        \n",
    "    def _preprocess_and_predict(self, img):\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        return self.model.predict(x)\n",
    "    \n",
    "    def search(self, x, k=5):\n",
    "        d, ixs = self.index.search(x, k)\n",
    "        paths = [self.paths[ix] for ix in ixs[0]]\n",
    "        return d, paths\n",
    "    \n",
    "    def search_from_path(self, path, k=5):\n",
    "        img = image.load_img(path, target_size=self.model_input_size)\n",
    "        x = self._preprocess_and_predict(img)\n",
    "        return self.search(x, k)\n",
    "        \n",
    "    def search_from_url(self, url, k=5):\n",
    "        with tempfile.NamedTemporaryFile() as f:\n",
    "            urllib.request.urlretrieve(url, f.name)\n",
    "            img = image.load_img(f.name, target_size=self.model_input_size)\n",
    "            x = self._preprocess_and_predict(img)\n",
    "            return self.search(x, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NearestNeighborsIndex(features_arr, paths, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_plot_from_url(url, k=5):\n",
    "    _, neighbor_paths = nn.search_from_url(url, k)\n",
    "    f, axs = plt.subplots(1, k + 1, figsize=(3*k, 10))\n",
    "    display_from_url(url, axs[0])\n",
    "    axs[0].axis('off')\n",
    "    for ax, neighbor_path in zip(axs[1:], neighbor_paths):\n",
    "        display_from_path(neighbor_path, ax)\n",
    "        ax.axis('off')\n",
    "    return neighbor_paths\n",
    "\n",
    "def search_and_plot_from_path(path, k=5):\n",
    "    _, neighbor_paths = nn.search_from_path(path, k)\n",
    "    f, axs = plt.subplots(1, k + 1, figsize=(3*k, 10))\n",
    "    display_from_path(path, axs[0])\n",
    "    for ax, neighbor_path in zip(axs[1:], neighbor_paths):\n",
    "        display_from_path(neighbor_path, ax)  \n",
    "    return neighbor_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_and_plot_from_url('https://img.letgo.com/images/b3/9a/01/67/b39a0167d370e3a220982d94c99bceb0.jpeg?impolicy=img_600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_and_plot_from_path(paths[-1], 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_in_prod",
   "language": "python",
   "name": "ml_in_prod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
